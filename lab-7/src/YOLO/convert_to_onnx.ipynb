{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "\n",
    "class F110_YOLO(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F110_YOLO, self).__init__()  # 180x320x3\n",
    "        # TODO: Change the channel depth of each layer\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size = 4, padding = 1, stride = 2)  # 90x160x32\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size = 4, padding = 1, stride = 2)  # 45x80x64\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size = 4, padding = 1, stride = 2)  # 22x40x128\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.relu3 = nn.ReLU(inplace = True)\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size = 4, padding = 1, stride = 2)  # 11x20x256\n",
    "        self.batchnorm4 = nn.BatchNorm2d(256)\n",
    "        self.relu4 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size = 4, padding = 1, stride = 2)  # 5x10x512\n",
    "        self.batchnorm5 = nn.BatchNorm2d(512)\n",
    "        self.relu5 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(512, 1024, kernel_size = 3, padding = 1, stride = 1)  # 5x10x1024\n",
    "        self.batchnorm6 = nn.BatchNorm2d(1024)\n",
    "        self.relu6 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv7 = nn.ConvTranspose2d(1024, 256, kernel_size = 3, padding = 1, stride = 1)  # 5x10x256\n",
    "        self.batchnorm7 = nn.BatchNorm2d(256)\n",
    "        self.relu7 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv8 = nn.ConvTranspose2d(256, 64, kernel_size = 3, padding = 1, stride = 1)  # 5x10x64\n",
    "        self.batchnorm8 = nn.BatchNorm2d(64)\n",
    "        self.relu8 = nn.ReLU(inplace = True)\n",
    "\n",
    "        self.conv9 = nn.Conv2d(64, 8, kernel_size = 1, padding = 0, stride = 1)  # 5x10x8\n",
    "        self.relu9 = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        debug = 0 # change this to 1 if you want to check network dimensions\n",
    "        if debug == 1: print(0, x.shape)\n",
    "        x = torch.relu(self.batchnorm1(self.conv1(x)))\n",
    "        if debug == 1: print(1, x.shape)\n",
    "        x = torch.relu(self.batchnorm2(self.conv2(x)))\n",
    "        if debug == 1: print(2, x.shape)\n",
    "        x = torch.relu(self.batchnorm3(self.conv3(x)))\n",
    "        if debug == 1: print(3, x.shape)\n",
    "        x = torch.relu(self.batchnorm4(self.conv4(x)))\n",
    "        if debug == 1: print(4, x.shape)\n",
    "        x = torch.relu(self.batchnorm5(self.conv5(x)))\n",
    "        if debug == 1: print(5, x.shape)\n",
    "        x = torch.relu(self.batchnorm6(self.conv6(x)))\n",
    "        if debug == 1: print(6, x.shape)\n",
    "        x = torch.relu(self.batchnorm7(self.conv7(x)))\n",
    "        if debug == 1: print(7, x.shape)\n",
    "        x = torch.relu(self.batchnorm8(self.conv8(x)))\n",
    "        if debug == 1: print(8, x.shape)\n",
    "        x = self.conv9(x)\n",
    "        if debug == 1: print(9, x.shape)\n",
    "        x = torch.cat([x[:, 0:3, :, :], torch.sigmoid(x[:, 3:5, :, :])], dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def get_loss(self, result, truth, lambda_coord = 5, lambda_noobj = 1):\n",
    "        x_loss = (result[:, 1, :, :] - truth[:, 1, :, :]) ** 2\n",
    "        y_loss = (result[:, 2, :, :] - truth[:, 2, :, :]) ** 2\n",
    "        w_loss = (torch.sqrt(result[:, 3, :, :]) - torch.sqrt(truth[:, 3, :, :])) ** 2\n",
    "        h_loss = (torch.sqrt(result[:, 4, :, :]) - torch.sqrt(truth[:, 4, :, :])) ** 2\n",
    "        class_loss_obj = truth[:, 0, :, :] * (truth[:, 0, :, :] - result[:, 0, :, :]) ** 2\n",
    "        class_loss_noobj = (1 - truth[:, 0, :, :]) * lambda_noobj * (truth[:, 0, :, :] - result[:, 0, :, :]) ** 2\n",
    "\n",
    "        total_loss = torch.sum(lambda_coord * truth[:, 0, :, :] * (x_loss + y_loss + w_loss + h_loss) + class_loss_obj + class_loss_noobj)\n",
    "        \n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = F110_YOLO()\n",
    "model_save_name = 'best_model.pt'\n",
    "path = \"\" + model_save_name\n",
    "model.load_state_dict(torch.load(path))\n",
    "model = model.to(device)\n",
    "\n",
    "# Convert the model to ONNX format\n",
    "ONNX_FILE_PATH = 'yolo.onnx'\n",
    "dummy_input = torch.randn(1, 3, 180, 320, requires_grad=True).to(device)\n",
    "torch.onnx.export(model, dummy_input, ONNX_FILE_PATH, input_names=['input'], output_names=['output'], export_params=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model converted fine\n",
    "import onnx\n",
    "onnx_model = onnx.load(ONNX_FILE_PATH)\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nlp_2024_03_16)",
   "language": "python",
   "name": "nlp_2024_03_16"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
